{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdhanush27/Deepfake-audio-detection/blob/main/Sem7Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download Data\n",
        "# @markdown ---\n",
        "# @markdown > Download dataset from github\n",
        "# @markdown ---\n",
        "!git clone https://github.com/gdhanush27/Deepfake-audio-detection.git\n",
        "from google.colab import output\n",
        "output.clear()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5lVFuwHlDg7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load data\n",
        "# @markdown ---\n",
        "# @markdown > Load data\n",
        "# @markdown ---\n",
        "\n",
        "img_size_ = 32 # @param [24,32,64,128] {type:\"raw\"}\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, TimeDistributed, concatenate\n",
        "import joblib\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import google\n",
        "import numpy as np\n",
        "\n",
        "save_path = f'/content/Deepfake-audio-detection/DataFiles/dataset_{img_size_}_{img_size_}.pkl'\n",
        "try:\n",
        "  data = joblib.load(save_path)\n",
        "except FileNotFoundError:\n",
        "  print(\"Data Not Found\")\n",
        "else:\n",
        "  cnn_images = data['cnn_images']\n",
        "  rnn_images = data['rnn_images']\n",
        "  labels = data['labels']\n",
        "  X_cnn_train, X_cnn_val, X_rnn_train, X_rnn_val, y_train, y_val = train_test_split(\n",
        "    cnn_images, rnn_images, labels, test_size=0.2, random_state=42)\n",
        "  class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "  class_weight_dict = dict(enumerate(class_weights))\n",
        "  print(f\"Data Loaded Successfully\\nData : /content/drive/MyDrive/dataset_{img_size_}_{img_size_}.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NPSxB-QIfRu",
        "outputId": "29f85da7-a46d-418f-a23e-125dc87884a2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded Successfully\n",
            "Data : /content/drive/MyDrive/dataset_32_32.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ---\n",
        "# @markdown > Only Run this, If data not found...\n",
        "# @markdown ---\n",
        "# @title Data Preprocessing *ONLY IF NECESSARY*\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Dropout, TimeDistributed, concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "prepared_dir = \"/content/drive/MyDrive/DatasetUpdated\"\n",
        "\n",
        "cnn_dir = os.path.join(prepared_dir, \"CNN\")\n",
        "rnn_dir = os.path.join(prepared_dir, \"RNN\")\n",
        "\n",
        "def load_data(cnn_dir, rnn_dir, max_rnn_images=100):\n",
        "    cnn_images = []\n",
        "    rnn_images = []\n",
        "    labels = []\n",
        "    c = 1\n",
        "    for class_type in [\"REAL\", \"FAKE\"]:\n",
        "        cnn_class_dir = os.path.join(cnn_dir, class_type)\n",
        "        rnn_class_dir = os.path.join(rnn_dir, class_type)\n",
        "\n",
        "        for cnn_file in os.listdir(cnn_class_dir):\n",
        "            cnn_path = os.path.join(cnn_class_dir, cnn_file)\n",
        "            rnn_subdir = os.path.join(rnn_class_dir, cnn_file.split(\".\")[0])\n",
        "\n",
        "            if os.path.exists(rnn_subdir):\n",
        "                # Load CNN image\n",
        "                cnn_img = tf.keras.preprocessing.image.load_img(cnn_path, target_size=(img_size_, img_size_))\n",
        "                cnn_img = tf.keras.preprocessing.image.img_to_array(cnn_img) / 255.0\n",
        "\n",
        "                # Load RNN images (each segment)\n",
        "                rnn_imgs = []\n",
        "                for rnn_file in os.listdir(rnn_subdir):\n",
        "                    rnn_path = os.path.join(rnn_subdir, rnn_file)\n",
        "                    rnn_img = tf.keras.preprocessing.image.load_img(rnn_path, target_size=(img_size_, img_size_))\n",
        "                    rnn_img = tf.keras.preprocessing.image.img_to_array(rnn_img) / 255.0\n",
        "                    rnn_imgs.append(rnn_img)\n",
        "\n",
        "                # Pad or truncate the RNN images to ensure equal length\n",
        "                if len(rnn_imgs) < max_rnn_images:\n",
        "                    rnn_imgs.extend([np.zeros_like(rnn_imgs[0])] * (max_rnn_images - len(rnn_imgs)))\n",
        "                else:\n",
        "                    rnn_imgs = rnn_imgs[:max_rnn_images]\n",
        "\n",
        "                # Append to lists\n",
        "                cnn_images.append(cnn_img)\n",
        "                rnn_images.append(rnn_imgs)\n",
        "                labels.append(0 if class_type == \"REAL\" else 1)\n",
        "                if c%10==0:\n",
        "                  print(c,\"Completed\")\n",
        "                c+=1\n",
        "    # Convert to numpy arrays\n",
        "    cnn_images = np.array(cnn_images)\n",
        "    rnn_images = np.array(rnn_images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return cnn_images, np.array(rnn_images), labels\n",
        "\n",
        "# Load the data\n",
        "cnn_images, rnn_images, labels = load_data(cnn_dir, rnn_dir)\n",
        "\n",
        "save_path = f'/content/drive/MyDrive/dataset_{img_size_}_{img_size_}.pkl'\n",
        "# print(save_path)\n",
        "data = {\n",
        "    'cnn_images': cnn_images,\n",
        "    'rnn_images': rnn_images,\n",
        "    'labels': labels\n",
        "}\n",
        "\n",
        "joblib.dump(data, save_path)\n",
        "print(f\"Data saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UluOJE6_bW3A",
        "outputId": "7c840fd2-8292-4db2-bfa2-1898fa69f640",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/dataset_64_64.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Compression *ONLY IF NECESSARY*\n",
        "# @markdown ---\n",
        "# @markdown Compression level (from 1 to 9, with 9 being maximum compression but slower)\n",
        "# @markdown\n",
        "# @markdown ---\n",
        "comp_lvl = 2 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "save_path = f'/content/drive/MyDrive/dataset_{img_size_}_{img_size_}_compression_level_{comp_lvl}.pkl'\n",
        "data = {\n",
        "    'cnn_images': cnn_images,\n",
        "    'rnn_images': rnn_images,\n",
        "    'labels': labels\n",
        "}\n",
        "joblib.dump(data, save_path, compress=('zlib', comp_lvl))\n",
        "print(f\"Compresssed to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "dfYo-gSb63gu",
        "outputId": "1e02117c-2f96-4c53-ab81-0a0fffa5e786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compresssed to /content/drive/MyDrive/dataset_128_128_compression_level_3.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Training\n",
        "# @markdown ---\n",
        "# @markdown > Train the model\n",
        "# @markdown ---\n",
        "\n",
        "num_epochs_ = 1 # @param [1,5,10,25,100] {\"type\":\"raw\",\"allow-input\":true}\n",
        "batch_size_ = 64 # @param [\"2\",\"4\",\"8\",\"16\",\"32\",\"64\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "\n",
        "cnn_input_shape = (img_size_, img_size_, 3)\n",
        "rnn_input_shape = (100, img_size_, img_size_, 3)\n",
        "\n",
        "cnn_input = Input(shape=cnn_input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "# x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "# x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "cnn_out = Flatten()(x)\n",
        "\n",
        "rnn_input = Input(shape=rnn_input_shape)\n",
        "y = TimeDistributed(Conv2D(32, (3, 3), activation='relu'))(rnn_input)\n",
        "# y = TimeDistributed(MaxPooling2D((2, 2)))(y)\n",
        "# y = TimeDistributed(Conv2D(64, (3, 3), activation='relu'))(y)\n",
        "y = TimeDistributed(MaxPooling2D((2, 2)))(y)\n",
        "y = TimeDistributed(Flatten())(y)\n",
        "rnn_out = LSTM(128)(y)\n",
        "\n",
        "combined = concatenate([cnn_out, rnn_out])\n",
        "z = Dense(64, activation='relu')(combined)\n",
        "z = Dense(16, activation='relu')(z)\n",
        "output = Dense(1, activation='sigmoid')(z)\n",
        "model = Model(inputs=[cnn_input, rnn_input], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    [X_cnn_train, X_rnn_train],\n",
        "    y_train,\n",
        "    # validation_data=([X_cnn_val, X_rnn_val], y_val),\n",
        "    epochs=num_epochs_,\n",
        "    batch_size= batch_size_,\n",
        "    class_weight=class_weight_dict\n",
        ")"
      ],
      "metadata": {
        "id": "SqkZM_iYcajY",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e2406a6-4ab7-4b7c-f26a-8d1f3d5ee07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node gradient_tape/functional_1/time_distributed_2_1/strided_slice_97/StridedSliceGrad defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-3-8d9dce4ecaf8>\", line 37, in <cell line: 37>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 70, in train_step\n\nOOM when allocating tensor with shape[100,51,15,15,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/functional_1/time_distributed_2_1/strided_slice_97/StridedSliceGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_13386]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8d9dce4ecaf8>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mX_cnn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_rnn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/functional_1/time_distributed_2_1/strided_slice_97/StridedSliceGrad defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-3-8d9dce4ecaf8>\", line 37, in <cell line: 37>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 70, in train_step\n\nOOM when allocating tensor with shape[100,51,15,15,32] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/functional_1/time_distributed_2_1/strided_slice_97/StridedSliceGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_iterator_13386]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluate the model\n",
        "loss, accuracy = model.evaluate([X_cnn_val, X_rnn_val], y_val)\n",
        "print(f\"Validation Loss: {loss}\")\n",
        "print(f\"Validation Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "wtMWDoSDkjrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a31638-3345-43a4-9c7b-2a4ece67fb7f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.8462 - loss: 0.6854\n",
            "Validation Loss: 0.6854361295700073\n",
            "Validation Accuracy: 0.8461538553237915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save model\n",
        "model.save('/content/drive/MyDrive/fusion_model.h5')"
      ],
      "metadata": {
        "id": "IZcDrUigyL21",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot Graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y3jKuYAoyHjl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}